# SIP AI Agent - Cursor Rules (Production-Safe IDE Assistant)

## Project Overview
This is a SIP AI Agent that integrates with OpenAI's API for real-time voice interactions. The project uses Python, PJSIP for SIP protocol handling, and provides both legacy and realtime OpenAI API support.

## 🚨 CRITICAL: Production-Safe IDE Assistant Rules

### ❌ NEVER DO (Local Execution Prohibited)
- **NEVER run code locally**: No dev servers, build steps, package managers, or database migrations
- **NEVER execute shell commands**: No `npm`, `pip`, `make`, `docker`, or system commands
- **NEVER run tests locally**: All testing happens in CI only
- **NEVER auto-run linting/formatting**: Only in CI workflows
- **NEVER invoke package managers**: No `npm install`, `pip install`, etc.

### ✅ ALWAYS DO (Stateless & CI-Driven)
- **Stateless editing**: Make atomic, reversible changes via patches/diffs
- **E2E-first debugging**: Use Playwright tests as source of truth
- **CI-driven workflow**: All heavy tasks happen in GitHub Actions
- **Production-ready output**: Typed APIs, strict lint/format, locked dependencies
- **Accessibility enforcement**: WCAG AA compliance, keyboard nav, color contrast

### 🔧 E2E Playwright Rules (Source of Truth)
- Use `getByRole`/`getByLabel`/`getByTestId` with `hasText` instead of brittle CSS
- Add explicit waits for network/UI stability (`page.waitForResponse`, `locator.waitFor`)
- Reduce flakiness: avoid `nth()` and time-based sleeps; prefer deterministic signals
- Mark slow/speculative tests with `test.slow()` and parallelize with shards in CI
- Keep traces: `trace:on-first-retry`. Always attach screenshots on failure
- Enforce accessibility: headings hierarchy, color contrast, keyboard navigation

### 📋 Every PR Checklist (Automated)
- [ ] Remove unused code, files, and configuration
- [ ] Delete caches and generated artifacts from repo
- [ ] Ensure `npm ci`/`pip install --no-cache-dir` works in CI only
- [ ] Lint and format pass in CI; do NOT auto-run locally
- [ ] All unit/integration/e2e tests pass in CI (upload traces on failure)
- [ ] Security: no plaintext secrets, good .gitignore, minimal tokens with least privilege

### 🛠️ When Tests Fail
1. Read CI artifacts (HTML report, traces, screenshots, console logs)
2. Propose fixes with exact files/lines to change
3. If page/action is flaky, add explicit waits and strict locators
4. Never increase global timeouts before attempting deterministic sync points
5. If accessibility failures point to contrast, propose WCAG AA-compliant token updates

### 🔄 Workflow Integration
- When a task requires running something, write/update GitHub Actions workflows
- Request user to push and let CI run the pipeline
- Provide diffs in unified patch format when suggesting changes
- Keep repo production-ready: typed APIs, strict lint/format, locked dependencies, reproducible builds

## Architecture
- **Main Agent**: `app/agent_new.py` - Enhanced main application with comprehensive error handling
- **Configuration**: `app/config.py` - Typed configuration using Pydantic
- **SIP Client**: `app/sip_client.py` - Enhanced SIP client with reconnection and NAT traversal
- **OpenAI Agent**: `app/openai_agent.py` - OpenAI API integration with realtime support
- **Monitoring**: `app/monitor.py` - Enhanced monitoring with health checks and metrics
- **Metrics**: `app/metrics.py` - Prometheus metrics collection
- **Logging**: `app/logging_config.py` - Structured logging with correlation IDs
- **Health**: `app/health.py` - Health monitoring and diagnostics

## Code Style & Standards
- Use Python 3.9+ features
- Follow PEP 8 with Black formatting (line length 88)
- Use type hints for all function parameters and return values
- Use structured logging with correlation IDs
- Write comprehensive docstrings for all public functions
- Use async/await for I/O operations
- Handle all exceptions gracefully with proper logging

## Dependencies
- **Core**: pjsua2, pyaudio, pydub, websockets
- **OpenAI**: openai>=1.0.0
- **Configuration**: pydantic, pydantic-settings, python-dotenv
- **Monitoring**: flask, structlog, prometheus-client
- **Testing**: pytest, pytest-asyncio, pytest-mock, httpx
- **Development**: black, isort, mypy, flake8, pre-commit

## Configuration
All configuration is handled through Pydantic settings in `app/config.py`. Environment variables are loaded from `.env` file with validation.

Key configuration categories:
- SIP settings (domain, user, password, advanced options)
- Audio settings (sample rate, channels, frame duration)
- OpenAI settings (API key, mode, model, voice)
- Monitoring settings (host, port, log levels)
- Observability settings (metrics, structured logging)

## Testing
- Write unit tests for all modules in `tests/`
- Use pytest fixtures for common test objects
- Mock external dependencies (SIP, OpenAI, WebSocket)
- Test error conditions and edge cases
- Use async test fixtures for async code
- Maintain >80% code coverage

## SIP Protocol
- Uses PJSIP library for SIP protocol handling
- Supports registration with automatic reconnection
- Handles incoming calls with proper state management
- Supports multiple codecs (PCMU, PCMA, G.722, L16)
- Includes NAT traversal support (STUN/TURN/ICE)
- Supports SRTP encryption when enabled

## Audio Pipeline
- 16-bit PCM at 16kHz sample rate
- 20ms frame duration (320 samples per frame)
- Backpressure handling to prevent queue overflow
- Graceful shutdown with proper cleanup
- Audio dropouts are tracked and logged

## OpenAI Integration
- Supports both legacy and realtime APIs
- Realtime API requires proper session configuration
- Voice validation for realtime mode
- Token usage tracking and metrics
- WebSocket connection management with error handling

## Monitoring & Observability
- Structured JSON logging with correlation IDs
- Prometheus metrics for all key operations
- Health checks for all components
- Real-time dashboard at `/dashboard`
- Health endpoint at `/healthz`
- Metrics endpoint at `/metrics`

## Error Handling
- All operations should be wrapped in try-catch blocks
- Log errors with appropriate severity levels
- Use correlation IDs to trace errors across components
- Implement retry logic with exponential backoff
- Graceful degradation when services are unavailable

## Security
- Never log sensitive information (passwords, API keys)
- Validate all input parameters
- Use secure defaults for all configurations
- Regular security scanning with bandit and safety

## Development Workflow (Production-Safe)

### 🔄 CI-First Development Process
1. **Code Changes**: Make atomic, reversible edits with clear rationale in comments
2. **GitHub Actions**: All heavy operations (tests, builds, linting) happen in CI
3. **Push & Verify**: Push changes and let CI run the complete pipeline
4. **Artifact Analysis**: Review CI artifacts (test reports, traces, screenshots) for failures
5. **Iterative Fixes**: Make targeted fixes based on CI feedback, never run locally

### 🧹 Cleanup & Maintenance
- **Dead Code Removal**: Remove unused imports, functions, files in separate PR labeled `chore: cleanup`
- **Cache Management**: Delete `__pycache__/`, `node_modules/`, `.coverage/`, `dist/` from repo
- **Artifact Cleanup**: Remove generated files, build outputs, and temporary files
- **Dependency Hygiene**: Keep `requirements.txt`, `package-lock.json` locked and minimal

### 🔒 Security & Compliance
- **Secrets Management**: Never log passwords, API keys, or sensitive data
- **Input Validation**: Validate all parameters and sanitize user inputs
- **Dependency Scanning**: Use `safety`, `bandit` in CI for security checks
- **Least Privilege**: Use minimal tokens with restricted scopes

### 📊 Quality Gates (CI-Only)
- **Code Quality**: Black formatting, isort, mypy, flake8 - all in CI
- **Test Coverage**: Maintain >80% coverage with pytest
- **E2E Validation**: Playwright tests must pass with traces on failure
- **Accessibility**: WCAG AA compliance enforced in E2E tests
- **Performance**: Monitor metrics and implement cleanup patterns

## Common Patterns

### Async Function Structure
```python
async def async_function(param: str) -> bool:
    """Async function with proper error handling."""
    try:
        # Implementation
        return True
    except Exception as e:
        logger.error("Error in async_function", 
                    param=param, error=str(e))
        return False
```

### Structured Logging
```python
logger.info("Operation completed", 
           correlation_id=correlation_id,
           operation="operation_name",
           duration=duration)
```

### Configuration Access
```python
from config import get_settings
settings = get_settings()
# Use settings.some_setting
```

### Metrics Recording
```python
from metrics import get_metrics
metrics = get_metrics()
metrics.record_some_metric(value)
```

### Health Checks
```python
from health import get_health_monitor
monitor = get_health_monitor()
report = await monitor.run_health_checks()
```

### E2E Test Patterns (Playwright)
```typescript
// ✅ GOOD: Use semantic selectors with explicit waits
test('should handle user interaction', async ({ page }) => {
  await page.goto('/');
  await page.waitForLoadState('networkidle');
  
  const button = page.getByRole('button', { name: 'Submit' });
  await expect(button).toBeVisible();
  await button.click();
  
  await page.waitForResponse(response => 
    response.url().includes('/api/submit') && response.status() === 200
  );
});

// ❌ BAD: Brittle CSS selectors and time-based waits
test('bad example', async ({ page }) => {
  await page.goto('/');
  await page.waitForTimeout(5000); // Don't do this
  await page.click('.btn-submit'); // Too brittle
});
```

### Accessibility Test Patterns
```typescript
test.describe('[a11y] Accessibility', () => {
  test('should be keyboard navigable', async ({ page }) => {
    await page.goto('/');
    await page.keyboard.press('Tab');
    const focused = page.locator(':focus');
    await expect(focused).toHaveCount(1);
  });

  test('should have proper heading structure', async ({ page }) => {
    await page.goto('/');
    const h1 = page.getByRole('heading', { level: 1 });
    await expect(h1).toBeVisible();
  });

  test('should have proper color contrast', async ({ page }) => {
    await page.goto('/');
    // Check CSS variables for WCAG AA compliance
    const contrastToken = await page.evaluate(() => 
      getComputedStyle(document.documentElement)
        .getPropertyValue('--color-contrast-threshold')
    );
    expect(contrastToken).toBeTruthy();
  });
});
```

## File Organization
- Keep related functionality in the same module
- Use clear, descriptive names for files and functions
- Separate concerns (SIP, OpenAI, monitoring, etc.)
- Import only what you need
- Use absolute imports from the app package

## Performance Considerations
- Use async I/O for all network operations
- Implement proper backpressure for audio queues
- Cache frequently accessed configuration values
- Use connection pooling where applicable
- Monitor memory usage and implement cleanup

## Deployment
- Docker container with multi-stage build
- Health checks for container orchestration
- Environment variable configuration
- Proper signal handling for graceful shutdown
- Resource limits and monitoring

## Troubleshooting (CI-First Approach)

### 🔍 Debugging Failed Tests
1. **CI Artifact Analysis**: Download and review HTML reports, traces, screenshots
2. **Console Logs**: Check browser console for JavaScript errors
3. **Network Issues**: Verify API responses and WebSocket connections
4. **Timing Issues**: Add explicit waits instead of increasing timeouts
5. **Flaky Tests**: Use deterministic signals, avoid `nth()` selectors

### 🚨 Common E2E Issues & Solutions
- **Element Not Found**: Use `getByRole`/`getByTestId` instead of CSS selectors
- **Timeout Errors**: Add `page.waitForLoadState('networkidle')` before interactions
- **Race Conditions**: Wait for specific responses with `page.waitForResponse()`
- **Accessibility Failures**: Check heading hierarchy, color contrast, keyboard nav

### 📊 Monitoring & Health Checks
- Check logs for correlation IDs to trace issues
- Use health endpoint to verify system status (`/healthz`)
- Monitor metrics for performance issues (`/metrics`)
- Validate configuration through CI validation steps
- Test SIP connectivity separately from OpenAI integration

### 🔧 CI/CD Integration
- **GitHub Actions**: All builds, tests, and deployments happen in CI
- **Artifact Storage**: Test reports, traces, and screenshots uploaded on failure
- **Parallel Execution**: Use shards for E2E tests, workers for unit tests
- **Security Scanning**: Automated dependency and vulnerability checks
- **Quality Gates**: Code coverage, linting, and accessibility checks

## Future Considerations
- Add support for additional codecs
- Implement call recording functionality
- Add support for multiple simultaneous calls
- Enhance NAT traversal options
- Add more detailed analytics and reporting
